{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating 2 floating point tensors (constant nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(), dtype=float32) Tensor(\"Const_3:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, dtype=tf.float32)\n",
    "node2 = tf.constant(4.0) # it is tf.float32 implicitly\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar los nodos, hay que lanzar el grafo computacional en una session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las operaciones entre tensores (como por ejemplo los tensores constantes ya definidos) también son nodos del grafo. Definimos un nodo \"suma\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3: Tensor(\"Add:0\", shape=(), dtype=float32)\n",
      "sess.run(node3): 7.0\n"
     ]
    }
   ],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "print(\"node3:\",node3)\n",
    "print(\"sess.run(node3):\", sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lugar de constantes, podemos definir variables, como placeholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.placeholder(tf.float32)\n",
    "b=tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + es un shortcut de tf.add(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los argumentos, o valores de las variables, los pasamos con un diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(adder_node, {a:3, b:4.5}))\n",
    "print(sess.run(adder_node, {a:[1,3], b:[2,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos otra operación al grafo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.5\n"
     ]
    }
   ],
   "source": [
    "add_and_triple = adder_node * 3.\n",
    "print(sess.run(add_and_triple, {a:3, b:4.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetro de un modelo de \"machine learning\", como son los pesos y bias de una red neuronal (W,b), se llaman parámetros entrenables, y se definen en tensor flow como Variable. Con Variables y Placeholders definimos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable([.3],dtype=tf.float32)\n",
    "b = tf.Variable([-.3],dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las constantes se inicializan al llamar tf.constant, pero no así las variables al llamar tf.Variable. Para inicializar las variables de un programa de TensorFlow, hay que utilizar una función especial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables se inicializan al llamar la función sess.run.\n",
    "Como x es un placeholder, podemos evaluar el modelo para varios valores de x al mismo tiempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(linear_model,{x:[1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la variable que contiene los target para entrenar el modelo, y, y la función de coste, como suma cuadrática de residuos entre el resultado del modelo y el target (y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)  #reduce_sum: suma a lo largo de una dimensión del tensor\n",
    "print(sess.run(loss,{x:[1, 2, 3, 4], y:[0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular el resultado para otros valores de los parámetros W y b. Para cambiar estos valores se utiliza la función tf.assign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x:[1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora aplicaremos gradient descent para obtener estos parámetros que optimizan el modelo. Vamos a hacer un entrenamiento con la API tf.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "sess.run(init) # reseteamos los parámetros a sus valores por defecto\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x:[1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "    \n",
    "print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponemos en un bloque todo el proceso anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Model parameters\n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "# Model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# loss\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# training data\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "# training loop\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) # reset values to wrong\n",
    "for i in range(1000):\n",
    "  sess.run(train, {x: x_train, y: y_train})\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libreria tf.estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta libreria contiene el ecosistema de machine learning: entrenamiento, evaluación, manejo de datos. Contiene varios modelos definidos. Veamos ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_session_config': None, '_model_dir': './output', '_save_checkpoints_secs': 600, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./output\\model.ckpt.\n",
      "INFO:tensorflow:loss = 9.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1492.54\n",
      "INFO:tensorflow:loss = 0.141233, step = 101 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 1785.73\n",
      "INFO:tensorflow:loss = 0.0212379, step = 201 (0.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 1923.07\n",
      "INFO:tensorflow:loss = 0.0020579, step = 301 (0.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 1886.78\n",
      "INFO:tensorflow:loss = 0.000126658, step = 401 (0.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 1818.17\n",
      "INFO:tensorflow:loss = 9.74265e-05, step = 501 (0.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 1818.18\n",
      "INFO:tensorflow:loss = 5.44358e-06, step = 601 (0.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 1960.78\n",
      "INFO:tensorflow:loss = 9.25066e-07, step = 701 (0.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 1754.37\n",
      "INFO:tensorflow:loss = 1.98901e-07, step = 801 (0.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 1886.77\n",
      "INFO:tensorflow:loss = 1.97318e-08, step = 901 (0.053 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ./output\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.70265e-09.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-29-08:22:10\n",
      "INFO:tensorflow:Restoring parameters from ./output\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-29-08:22:11\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 7.66889e-10, global_step = 1000, loss = 3.06755e-09\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-29-08:22:11\n",
      "INFO:tensorflow:Restoring parameters from ./output\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-29-08:22:12\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.00252726, global_step = 1000, loss = 0.010109\n",
      "train metrics: {'loss': 3.0675547e-09, 'average_loss': 7.6688866e-10, 'global_step': 1000}\n",
      "eval metrics: {'loss': 0.010109023, 'average_loss': 0.0025272558, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "\n",
    "# Declare list of features. We only have one numeric feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# linear classification, and many neural network classifiers and regressors.\n",
    "# The following code provides an estimator that does linear regression.\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns, model_dir='./output')\n",
    "\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use two data sets: one for training and one for evaluation\n",
    "# We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the  method and passing the\n",
    "# training data set.\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente utilizaremos tf.estimator con un modelo definido por el usuario, que puede hacerse como objeto de la clase tf.estimator.Estimator. En este caso definiremos un modelo de regresión lineal, que es el mismo que hemos utilizado de la propia librería, pero podríamos definir cualquier modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\C2416~1.GIN\\AppData\\Local\\Temp\\tmpts62cj4l\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_session_config': None, '_model_dir': 'C:\\\\Users\\\\C2416~1.GIN\\\\AppData\\\\Local\\\\Temp\\\\tmpts62cj4l', '_save_checkpoints_secs': 600, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\C2416~1.GIN\\AppData\\Local\\Temp\\tmpts62cj4l\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.18021338667, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1666.89\n",
      "INFO:tensorflow:loss = 0.011779787422, step = 101 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1639.32\n",
      "INFO:tensorflow:loss = 0.00198463306561, step = 201 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1694.94\n",
      "INFO:tensorflow:loss = 0.000475324594241, step = 301 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1562.43\n",
      "INFO:tensorflow:loss = 2.41956027215e-05, step = 401 (0.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 1818.2\n",
      "INFO:tensorflow:loss = 2.20223372335e-06, step = 501 (0.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 1785.69\n",
      "INFO:tensorflow:loss = 9.55390238309e-08, step = 601 (0.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 1785.69\n",
      "INFO:tensorflow:loss = 2.33649224659e-09, step = 701 (0.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 1960.74\n",
      "INFO:tensorflow:loss = 1.44562007159e-09, step = 801 (0.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 1724.14\n",
      "INFO:tensorflow:loss = 1.30808778845e-10, step = 901 (0.057 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\C2416~1.GIN\\AppData\\Local\\Temp\\tmpts62cj4l\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.32195767252e-12.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-29-08:30:33\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\C2416~1.GIN\\AppData\\Local\\Temp\\tmpts62cj4l\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-29-08:30:33\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.13045e-11\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-29-08:30:34\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\C2416~1.GIN\\AppData\\Local\\Temp\\tmpts62cj4l\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-29-08:30:34\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0101004\n",
      "train metrics: {'loss': 1.1304498e-11, 'global_step': 1000}\n",
      "eval metrics: {'loss': 0.010100436, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model_fn(features, labels, mode):\n",
    "  # Build a linear model and predict values\n",
    "  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "  y = W * features['x'] + b\n",
    "  # Loss sub-graph\n",
    "  loss = tf.reduce_sum(tf.square(y - labels))\n",
    "  # Training sub-graph\n",
    "  global_step = tf.train.get_global_step()\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "  train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "  # EstimatorSpec connects subgraphs we built to the\n",
    "  # appropriate functionality.\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# train\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
